#!/bin/bash
#SBATCH --begin=now
#SBATCH --spread-job 

###### IMPORTANT ###################
#SBATCH --output=e5_par_K80_fixed.%j.out
#SBATCH --job-name=e5_par_K80_fixed       ### name your job
# --gres=gpu:K80:1
# --nodelist=ge01
#SBATCH --nodes=2

#SBATCH --time=10:00:00            
#SBATCH --ntasks=2                
#SBATCH --cpus-per-task=1           ### every tasks has 2 threads
# --mem-per-cpu=32000
#SBATCH --partition=gpu

# To receive an email when job completes or fails
#SBATCH --mail-user=tinplay41@gmail.com,cmar0027@student.monash.edu
#SBATCH --mail-type=ALL


module load pytorch/1.5-cuda10


###### IMPORTANT ###################
srun python3 parallel.py --new --model_name par_K80_fixed --num_epochs 5
exit 0
